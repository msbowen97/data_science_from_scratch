{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8844044",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47a898d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/bowen/Documents/Data Science from Scratch/scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd4d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocessing import Preprocessor\n",
    "from methods import Method, Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb57363",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('C:/Users/bowen/Documents/Data Science from Scratch/data/spaceship-titanic/train.csv')\n",
    "testData = pd.read_csv('C:/Users/bowen/Documents/Data Science from Scratch/data/spaceship-titanic/test.csv')\n",
    "trainXdata = trainData[[col for col in trainData.columns if col != 'Transported']]\n",
    "testXdata = testData[[col for col in testData.columns if col != 'Transported']]\n",
    "trainYData = trainData['Transported'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2732eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainXdata[['Deck','RoomNo','ShipSide']] = trainXdata['Cabin'].str.split('/', expand=True)\n",
    "trainXdata[['GroupNo', 'GroupSize']] = trainXdata['PassengerId'].str.split('_', expand=True)\n",
    "trainXdata['Child'], trainXdata['Infant'] = (trainXdata['Age'] <= 18).astype(int), (trainXdata['Age'] <= 5).astype(int)\n",
    "trainXdata['TotalSpent'] = np.sum(trainXdata[['RoomService', 'FoodCourt', 'ShoppingMall','Spa','VRDeck']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6a7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testXdata[['Deck','RoomNo','ShipSide']] = testXdata['Cabin'].str.split('/', expand=True)\n",
    "testXdata[['GroupNo', 'GroupSize']] = testXdata['PassengerId'].str.split('_', expand=True)\n",
    "testXdata['Child'], testXdata['Infant'] = (testXdata['Age'] <= 18).astype(int), (testXdata['Age'] <= 5).astype(int)\n",
    "testXdata['TotalSpent'] = np.sum(testXdata[['RoomService', 'FoodCourt', 'ShoppingMall','Spa','VRDeck']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6914981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Preprocessor(dropCols = ['Name', 'Cabin', 'PassengerId', 'RoomNo', 'GroupNo', 'FoodCourt', 'ShoppingMall'],\n",
    "                onehotCols = ['HomePlanet', 'Destination', 'ShipSide'], directCols=['VIP', 'CryoSleep', 'GroupSize'],\n",
    "                ordinalCols = {'Deck': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']},\n",
    "                splitterMethod='kfold', splitGroups=5, imputerMethod='lazy', normalizerMethod='zscore', bagging=True)\n",
    "\n",
    "data(trainXdata, trainYData)\n",
    "\n",
    "normXtrain = data.transform(trainXdata, means=data.normalizer.means, stds=data.normalizer.stds)\n",
    "normXtest = data.transform(testXdata, means=data.normalizer.means, stds=data.normalizer.stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ab0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = Method(modelMethod='logreg', lossMethod='binary_cross_entropy', optimizerMethod='gd', \n",
    "                modelParams={}, \n",
    "                lossParams={}, \n",
    "                optimizerParams={'gradThreshold': 1e-5})\n",
    "validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "          validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "          binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5965030",
   "metadata": {},
   "outputs": [],
   "source": [
    "method(X=normXtrain, y=trainYData)\n",
    "yHat = method.predict(normXtest)\n",
    "yHat = (yHat > 0.5)*1#np.quantile(yHat, q=1-trainYData.mean())) * 1\n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], yHat)).T, columns=['PassengerId','Transported'])\n",
    "testSubmission.to_csv('gd_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e7db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = Method(modelMethod='logreg', lossMethod='binary_cross_entropy', optimizerMethod='mgd', \n",
    "                modelParams={}, \n",
    "                lossParams={}, \n",
    "                optimizerParams={'lossThreshold': 2e-6, 'maxEpochs':10000, 'gradThreshold':0})\n",
    "validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "          validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "          binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "method(X=normXtrain, y=trainYData)\n",
    "yHat = method.predict(normXtest)\n",
    "yHat = (yHat > 0.5)*1 # np.quantile(yHat, q=1-trainYData.mean())) * 1\n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], yHat)).T, columns=['PassengerId','Transported'])\n",
    "testSubmission.to_csv('mgd_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7724210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = Method(modelMethod='logreg', lossMethod='binary_cross_entropy', optimizerMethod='sa', \n",
    "                modelParams={}, \n",
    "                lossParams={}, \n",
    "                optimizerParams={'lossThreshold': 1e-5, 'maxEpochs':10000, 'gradThreshold':0, 'coolingRate':1e-6,\n",
    "                                 'temperature':0.05, 'initialGuess':'zeros', 'stepSize':1})\n",
    "\n",
    "validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "          validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "          binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6012c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "method(X=normXtrain, y=trainYData)\n",
    "yHat = method.predict(normXtest)\n",
    "yHat = (yHat > 0.5)*1 #np.quantile(yHat, q=1-trainYData.mean())) * 1\n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], yHat)).T, columns=['PassengerId','Transported'])\n",
    "testSubmission.to_csv('sa_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "148b14fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 2.66, Accuracy: 69.793, Precision: 68.008, Recall: 76.557\n",
      "Runtime: 3.42, Accuracy: 73.763, Precision: 78.755, Recall: 66.061\n",
      "Runtime: 1.91, Accuracy: 73.59, Precision: 76.119, Recall: 69.625\n",
      "Runtime: 1.83, Accuracy: 73.13, Precision: 73.904, Recall: 74.64\n",
      "Runtime: 1.88, Accuracy: 68.7, Precision: 66.235, Recall: 72.663\n",
      "Average Runtime: 2.34, Runtime Variance: 0.38508, Average Accuracy: 71.795, Accuracy Variance: 4.49286, Average Precision: 72.604, Precision Variance: 22.71348, Average Recall: 71.909, Recall Variance: 13.80931\n"
     ]
    }
   ],
   "source": [
    "method = Method(modelMethod='logreg', lossMethod='mse', optimizerMethod='rf', \n",
    "                modelParams={}, \n",
    "                lossParams={}, \n",
    "                optimizerParams={'maxTreeDepth':10, 'minGroupSize':5, 'nCols':0.33, 'nRows':0.67, 'nTrees':5,\n",
    "                                 'splitMethod':'histogram', 'classification': False, 'lossMethod':'mse'})\n",
    "\n",
    "validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "          validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "          binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73b4a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "method(X=normXtrain, y=trainYData)\n",
    "yHat = method.predict(normXtest)\n",
    "yHat = (yHat > 0.5) #np.quantile(yHat, q=1-trainYData.mean())) * 1\n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], yHat)).T, columns=['PassengerId','Transported'])\n",
    "# testSubmission.to_csv('rf_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de368eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 3.32, Accuracy: 55.121, Precision: 53.368, Recall: 92.412\n",
      "Runtime: 3.12, Accuracy: 51.956, Precision: 54.212, Recall: 33.598\n",
      "Runtime: 3.41, Accuracy: 54.488, Precision: 57.774, Recall: 37.201\n"
     ]
    }
   ],
   "source": [
    "method = Method(modelMethod='logreg', lossMethod='mse', optimizerMethod='gb', \n",
    "                modelParams={}, \n",
    "                lossParams={}, \n",
    "                optimizerParams={'maxTreeDepth':2, 'minGroupSize':5, 'maxBoosterDepth':10,\n",
    "                                 'splitMethod':'histogram', 'classification': False, 'lossMethod':'mse', 'lr':0.01})\n",
    "\n",
    "validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "          validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "          binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ae402",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionFiles = [x for x in os.listdir() if '_submission.csv' in x and 'ensemble' not in x]\n",
    "yPreds = np.zeros((len(submissionFiles), yHat.shape[0]))\n",
    "for i in range(len(submissionFiles)):\n",
    "    yPreds[i] = (pd.read_csv(submissionFiles[i])['Transported'])\n",
    "    \n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], np.round(np.mean(yPreds, axis=0))>0)).T, \n",
    "                              columns=['PassengerId','Transported'])\n",
    "testSubmission.to_csv('ensemble_submission.csv', index=False)\n",
    "\n",
    "agree = np.round((1 - np.sum(np.sum(np.abs(yPreds - np.mean(yPreds, axis=0)), axis=0) > 0) / yHat.shape[0]) * 100, 2)\n",
    "\n",
    "print(f'Percent Perfect Agreement: {agree}%')\n",
    "print(f'Total Variance Between Methods: {np.round(np.mean(np.var(yPreds, axis=0)), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb57846",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(yPreds - np.mean(yPreds, axis=0)), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
