{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a8844044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "47a898d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/bowen/Documents/Data Science from Scratch/scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cfd4d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocessing import Preprocessor\n",
    "from methods import Method, Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9cb57363",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('C:/Users/bowen/Documents/Data Science from Scratch/data/spaceship-titanic/train.csv')\n",
    "testData = pd.read_csv('C:/Users/bowen/Documents/Data Science from Scratch/data/spaceship-titanic/test.csv')\n",
    "trainXdata = trainData[[col for col in trainData.columns if col != 'Transported']]\n",
    "testXdata = testData[[col for col in testData.columns if col != 'Transported']]\n",
    "trainYData = trainData['Transported'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2732eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainXdata[['Deck','RoomNo','ShipSide']] = trainXdata['Cabin'].str.split('/', expand=True)\n",
    "trainXdata[['GroupNo', 'GroupSize']] = trainXdata['PassengerId'].str.split('_', expand=True)\n",
    "trainXdata['Child'], trainXdata['Infant'] = (trainXdata['Age'] <= 18).astype(int), (trainXdata['Age'] <= 5).astype(int)\n",
    "trainXdata['TotalSpent'] = np.sum(trainXdata[['RoomService', 'FoodCourt', 'ShoppingMall','Spa','VRDeck']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5a6a7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testXdata[['Deck','RoomNo','ShipSide']] = testXdata['Cabin'].str.split('/', expand=True)\n",
    "testXdata[['GroupNo', 'GroupSize']] = testXdata['PassengerId'].str.split('_', expand=True)\n",
    "testXdata['Child'], testXdata['Infant'] = (testXdata['Age'] <= 18).astype(int), (testXdata['Age'] <= 5).astype(int)\n",
    "testXdata['TotalSpent'] = np.sum(testXdata[['RoomService', 'FoodCourt', 'ShoppingMall','Spa','VRDeck']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6914981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Preprocessor(dropCols = ['Name', 'Cabin', 'PassengerId', 'RoomNo', 'GroupNo', 'FoodCourt', 'ShoppingMall'],\n",
    "                onehotCols = ['HomePlanet', 'Destination', 'ShipSide'], directCols=['VIP', 'CryoSleep', 'GroupSize'],\n",
    "                ordinalCols = {'Deck': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']},\n",
    "                splitterMethod='kfold', splitGroups=5, imputerMethod='lazy', normalizerMethod='zscore', bagging=True)\n",
    "\n",
    "data(trainXdata, trainYData)\n",
    "\n",
    "normXtrain = data.transform(trainXdata, means=data.normalizer.means, stds=data.normalizer.stds)\n",
    "normXtest = data.transform(testXdata, means=data.normalizer.means, stds=data.normalizer.stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ab3ab0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max epochs reached (10000)\n",
      "Runtime: 19.11, Accuracy: 80.61, Precision: 80.503, Recall: 83.569\n",
      "Max epochs reached (10000)\n",
      "Runtime: 20.64, Accuracy: 80.552, Precision: 77.253, Recall: 84.293\n",
      "Max epochs reached (10000)\n",
      "Runtime: 20.95, Accuracy: 80.667, Precision: 78.832, Recall: 85.039\n",
      "Max epochs reached (10000)\n",
      "Runtime: 24.11, Accuracy: 78.251, Precision: 77.612, Recall: 81.25\n",
      "Max epochs reached (10000)\n",
      "Runtime: 19.86, Accuracy: 79.919, Precision: 77.35, Recall: 84.088\n",
      "Average Runtime: 20.934, Runtime Variance: 2.93082, Average Accuracy: 80.0, Accuracy Variance: 0.83745, Average Precision: 78.31, Precision Variance: 1.52156, Average Recall: 83.648, Recall Variance: 1.66023\n"
     ]
    }
   ],
   "source": [
    "method = Method(modelMethod='logreg', lossMethod='binary_cross_entropy', optimizerMethod='gd', \n",
    "                modelParams={}, \n",
    "                lossParams={}, \n",
    "                optimizerParams={'gradThreshold': 1e-5})\n",
    "validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "          validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "          binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c5965030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max epochs reached (10000)\n"
     ]
    }
   ],
   "source": [
    "method(X=normXtrain, y=trainYData)\n",
    "yHat = method.predict(normXtest)\n",
    "yHat = (yHat > 0.5)*1#np.quantile(yHat, q=1-trainYData.mean())) * 1\n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], yHat)).T, columns=['PassengerId','Transported'])\n",
    "testSubmission.to_csv('gd_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d2e7db63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descent halted after 172 epochs as loss threshold reached (0.0 <= 2e-06)\n",
      "Runtime: 2.44, Accuracy: 80.898, Precision: 81.124, Recall: 83.243\n",
      "Descent halted after 323 epochs as loss threshold reached (0.0 <= 2e-06)\n",
      "Runtime: 4.87, Accuracy: 80.955, Precision: 77.486, Recall: 85.012\n",
      "Descent halted after 695 epochs as loss threshold reached (0.0 <= 2e-06)\n",
      "Runtime: 10.71, Accuracy: 80.898, Precision: 78.564, Recall: 86.164\n",
      "Descent halted after 161 epochs as loss threshold reached (0.0 <= 2e-06)\n",
      "Runtime: 2.42, Accuracy: 78.481, Precision: 77.885, Recall: 81.362\n",
      "Descent halted after 169 epochs as loss threshold reached (0.0 <= 2e-06)\n",
      "Runtime: 2.58, Accuracy: 79.977, Precision: 77.316, Recall: 84.321\n",
      "Average Runtime: 4.604, Runtime Variance: 10.18066, Average Accuracy: 80.242, Accuracy Variance: 0.90808, Average Precision: 78.475, Precision Variance: 1.93892, Average Recall: 84.02, Recall Variance: 2.66802\n"
     ]
    }
   ],
   "source": [
    "method = Method(modelMethod='logreg', lossMethod='binary_cross_entropy', optimizerMethod='mgd', \n",
    "                modelParams={}, \n",
    "                lossParams={}, \n",
    "                optimizerParams={'lossThreshold': 2e-6, 'maxEpochs':10000, 'gradThreshold':0})\n",
    "validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "          validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "          binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "17e8aa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descent halted after 153 epochs as loss threshold reached (0.0 <= 2e-06)\n"
     ]
    }
   ],
   "source": [
    "method(X=normXtrain, y=trainYData)\n",
    "yHat = method.predict(normXtest)\n",
    "yHat = (yHat > 0.5)*1 # np.quantile(yHat, q=1-trainYData.mean())) * 1\n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], yHat)).T, columns=['PassengerId','Transported'])\n",
    "testSubmission.to_csv('mgd_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7724210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max epochs reached (10000)\n",
      "Runtime: 19.72, Accuracy: 78.884, Precision: 80.197, Recall: 79.761\n",
      "Max epochs reached (10000)\n",
      "Runtime: 18.86, Accuracy: 79.171, Precision: 76.339, Recall: 82.014\n",
      "Max epochs reached (10000)\n",
      "Runtime: 19.7, Accuracy: 80.725, Precision: 79.036, Recall: 84.814\n",
      "Max epochs reached (10000)\n",
      "Runtime: 20.43, Accuracy: 75.777, Precision: 76.477, Recall: 76.562\n",
      "Max epochs reached (10000)\n",
      "Runtime: 19.84, Accuracy: 78.423, Precision: 78.125, Recall: 78.397\n",
      "Average Runtime: 19.71, Runtime Variance: 0.2516, Average Accuracy: 78.596, Accuracy Variance: 2.58458, Average Precision: 78.035, Precision Variance: 2.19762, Average Recall: 80.31, Recall Variance: 8.23962\n"
     ]
    }
   ],
   "source": [
    "method = Method(modelMethod='logreg', lossMethod='binary_cross_entropy', optimizerMethod='sa', \n",
    "                modelParams={}, \n",
    "                lossParams={}, \n",
    "                optimizerParams={'lossThreshold': 1e-5, 'maxEpochs':10000, 'gradThreshold':0, 'coolingRate':1e-6,\n",
    "                                 'temperature':0.05, 'initialGuess':'zeros', 'stepSize':1})\n",
    "\n",
    "validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "          validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "          binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ba6012c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max epochs reached (10000)\n"
     ]
    }
   ],
   "source": [
    "method(X=normXtrain, y=trainYData)\n",
    "yHat = method.predict(normXtest)\n",
    "yHat = (yHat > 0.5)*1 #np.quantile(yHat, q=1-trainYData.mean())) * 1\n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], yHat)).T, columns=['PassengerId','Transported'])\n",
    "testSubmission.to_csv('sa_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "148b14fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 109.6, Accuracy: 80.725, Precision: 81.466, Recall: 82.263\n",
      "Runtime: 135.18, Accuracy: 80.437, Precision: 78.721, Recall: 81.175\n",
      "Runtime: 123.93, Accuracy: 80.092, Precision: 79.479, Recall: 82.34\n",
      "Runtime: 126.65, Accuracy: 78.539, Precision: 80.301, Recall: 77.344\n",
      "Runtime: 119.96, Accuracy: 80.38, Precision: 79.148, Recall: 81.998\n",
      "Average Runtime: 123.064, Runtime Variance: 70.26418, Average Accuracy: 80.035, Accuracy Variance: 0.5996, Average Precision: 79.823, Precision Variance: 0.94326, Average Recall: 81.024, Recall Variance: 3.55617\n"
     ]
    }
   ],
   "source": [
    "method = Method(modelMethod='logreg', lossMethod='gini', optimizerMethod='rf', \n",
    "                modelParams={}, \n",
    "                lossParams={}, \n",
    "                optimizerParams={'maxTreeDepth':10, 'minGroupSize':5, 'nCols':0.33, 'nRows':0.67, 'nTrees':50,\n",
    "                                 'splitMethod':'full_sweep', 'classification': True, 'lossMethod':'mse'})\n",
    "\n",
    "validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "          validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "          binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "73b4a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "method(X=normXtrain, y=trainYData)\n",
    "yHat = method.predict(normXtest)\n",
    "yHat = (yHat > 0.5) #np.quantile(yHat, q=1-trainYData.mean())) * 1\n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], yHat)).T, columns=['PassengerId','Transported'])\n",
    "testSubmission.to_csv('rf_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5d885649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 30.16, Accuracy: 80.265, Precision: 80.704, Recall: 82.372\n",
      "Runtime: 31.44, Accuracy: 80.15, Precision: 77.627, Recall: 82.374\n",
      "Runtime: 30.61, Accuracy: 80.61, Precision: 79.362, Recall: 83.915\n",
      "Runtime: 30.72, Accuracy: 78.136, Precision: 78.043, Recall: 80.134\n",
      "Runtime: 31.56, Accuracy: 80.207, Precision: 78.438, Recall: 82.811\n",
      "Average Runtime: 30.898, Runtime Variance: 0.27826, Average Accuracy: 79.874, Accuracy Variance: 0.78046, Average Precision: 78.835, Precision Variance: 1.20301, Average Recall: 82.321, Recall Variance: 1.51386\n"
     ]
    }
   ],
   "source": [
    "method = Method(modelMethod='logreg', lossMethod='binary_cross_entropy', optimizerMethod='ga', \n",
    "                modelParams={}, \n",
    "                lossParams={}, \n",
    "                optimizerParams={'maxEpochs':normXtrain.shape[1]*20, 'thetaMin': -2, 'thetaMax': 2})\n",
    "\n",
    "validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "          validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "          binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f348f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "method(X=normXtrain, y=trainYData)\n",
    "yHat = method.predict(normXtest)\n",
    "yHat = (yHat > 0.5) #np.quantile(yHat, q=1-trainYData.mean())) * 1\n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], yHat)).T, columns=['PassengerId','Transported'])\n",
    "testSubmission.to_csv('ga_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1cc52c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: prob mean=0.503, grad std=0.500, yHat std=0.008\n",
      "iter 1: prob mean=0.503, grad std=0.500, yHat std=0.015\n",
      "iter 2: prob mean=0.503, grad std=0.499, yHat std=0.024\n",
      "iter 3: prob mean=0.503, grad std=0.499, yHat std=0.033\n",
      "iter 4: prob mean=0.503, grad std=0.498, yHat std=0.042\n",
      "iter 5: prob mean=0.503, grad std=0.498, yHat std=0.051\n",
      "iter 6: prob mean=0.503, grad std=0.497, yHat std=0.059\n",
      "iter 7: prob mean=0.503, grad std=0.497, yHat std=0.068\n",
      "iter 8: prob mean=0.503, grad std=0.497, yHat std=0.076\n",
      "iter 9: prob mean=0.503, grad std=0.496, yHat std=0.084\n",
      "Runtime: 3.03, Accuracy: 55.121, Precision: 53.368, Recall: 92.412\n",
      "iter 0: prob mean=0.502, grad std=0.500, yHat std=0.006\n",
      "iter 1: prob mean=0.502, grad std=0.500, yHat std=0.013\n",
      "iter 2: prob mean=0.502, grad std=0.500, yHat std=0.019\n",
      "iter 3: prob mean=0.502, grad std=0.499, yHat std=0.025\n",
      "iter 4: prob mean=0.502, grad std=0.499, yHat std=0.030\n",
      "iter 5: prob mean=0.502, grad std=0.499, yHat std=0.036\n",
      "iter 6: prob mean=0.502, grad std=0.499, yHat std=0.042\n",
      "iter 7: prob mean=0.502, grad std=0.499, yHat std=0.047\n",
      "iter 8: prob mean=0.502, grad std=0.499, yHat std=0.052\n",
      "iter 9: prob mean=0.502, grad std=0.499, yHat std=0.057\n",
      "Runtime: 3.27, Accuracy: 51.956, Precision: 54.212, Recall: 33.598\n",
      "iter 0: prob mean=0.503, grad std=0.500, yHat std=0.015\n",
      "iter 1: prob mean=0.503, grad std=0.499, yHat std=0.017\n",
      "iter 2: prob mean=0.503, grad std=0.499, yHat std=0.019\n",
      "iter 3: prob mean=0.503, grad std=0.499, yHat std=0.021\n",
      "iter 4: prob mean=0.503, grad std=0.499, yHat std=0.024\n",
      "iter 5: prob mean=0.503, grad std=0.499, yHat std=0.026\n",
      "iter 6: prob mean=0.503, grad std=0.498, yHat std=0.029\n",
      "iter 7: prob mean=0.503, grad std=0.498, yHat std=0.032\n",
      "iter 8: prob mean=0.503, grad std=0.498, yHat std=0.034\n",
      "iter 9: prob mean=0.503, grad std=0.498, yHat std=0.037\n",
      "Runtime: 3.4, Accuracy: 54.488, Precision: 57.774, Recall: 37.201\n",
      "iter 0: prob mean=0.502, grad std=0.500, yHat std=0.009\n",
      "iter 1: prob mean=0.502, grad std=0.500, yHat std=0.017\n",
      "iter 2: prob mean=0.502, grad std=0.499, yHat std=0.025\n",
      "iter 3: prob mean=0.502, grad std=0.499, yHat std=0.030\n",
      "iter 4: prob mean=0.502, grad std=0.499, yHat std=0.035\n",
      "iter 5: prob mean=0.502, grad std=0.498, yHat std=0.042\n",
      "iter 6: prob mean=0.502, grad std=0.498, yHat std=0.048\n",
      "iter 7: prob mean=0.502, grad std=0.498, yHat std=0.053\n",
      "iter 8: prob mean=0.502, grad std=0.498, yHat std=0.059\n",
      "iter 9: prob mean=0.502, grad std=0.497, yHat std=0.065\n",
      "Runtime: 3.98, Accuracy: 55.293, Precision: 63.696, Recall: 32.447\n",
      "iter 0: prob mean=0.506, grad std=0.500, yHat std=0.006\n",
      "iter 1: prob mean=0.506, grad std=0.500, yHat std=0.012\n",
      "iter 2: prob mean=0.506, grad std=0.500, yHat std=0.018\n",
      "iter 3: prob mean=0.506, grad std=0.499, yHat std=0.023\n",
      "iter 4: prob mean=0.506, grad std=0.499, yHat std=0.029\n",
      "iter 5: prob mean=0.506, grad std=0.499, yHat std=0.034\n",
      "iter 6: prob mean=0.506, grad std=0.499, yHat std=0.039\n",
      "iter 7: prob mean=0.506, grad std=0.499, yHat std=0.044\n",
      "iter 8: prob mean=0.506, grad std=0.499, yHat std=0.049\n",
      "iter 9: prob mean=0.506, grad std=0.499, yHat std=0.054\n",
      "Runtime: 3.87, Accuracy: 53.452, Precision: 70.93, Recall: 7.219\n",
      "Average Runtime: 3.51, Runtime Variance: 0.13012, Average Accuracy: 54.062, Accuracy Variance: 1.52513, Average Precision: 59.996, Precision Variance: 43.11294, Average Recall: 40.575, Recall Variance: 785.16482\n"
     ]
    }
   ],
   "source": [
    "# method = Method(modelMethod='logreg', lossMethod='mse', optimizerMethod='gb', \n",
    "#                 modelParams={}, \n",
    "#                 lossParams={}, \n",
    "#                 optimizerParams={'maxTreeDepth':2, 'minGroupSize':5, 'maxBoosterDepth':10,\n",
    "#                                  'splitMethod':'histogram', 'classification': False, 'lossMethod':'mse', 'lr':0.1})\n",
    "\n",
    "# validator = Validator(method=method, diagnosticParams={'metrics': ('accuracy', 'precision', 'recall')})\n",
    "\n",
    "# validator(trainXs=data.splitter.trainX, trainYs=data.splitter.trainY, \n",
    "#           validationXs=data.splitter.validationX, validationYs=data.splitter.validationY, \n",
    "#           binary=True, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "855ae402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ga_submission.csv', 'gd_submission.csv', 'mgd_submission.csv', 'rf_submission.csv', 'sa_submission.csv']\n",
      "Percent Perfect Agreement: 86.98%\n",
      "Total Variance Between Methods: 0.0224\n"
     ]
    }
   ],
   "source": [
    "submissionFiles = [x for x in os.listdir() if '_submission.csv' in x and 'ensemble' not in x]\n",
    "print(submissionFiles)\n",
    "yPreds = np.zeros((len(submissionFiles), yHat.shape[0]))\n",
    "for i in range(len(submissionFiles)):\n",
    "    yPreds[i] = (pd.read_csv(submissionFiles[i])['Transported'])\n",
    "    \n",
    "testSubmission = pd.DataFrame(np.vstack((testData['PassengerId'], np.round(np.mean(yPreds, axis=0))>0)).T, \n",
    "                              columns=['PassengerId','Transported'])\n",
    "testSubmission.to_csv('ensemble_submission.csv', index=False)\n",
    "\n",
    "agree = np.round((1 - np.sum(np.sum(np.abs(yPreds - np.mean(yPreds, axis=0)), axis=0) > 0) / yHat.shape[0]) * 100, 2)\n",
    "\n",
    "print(f'Percent Perfect Agreement: {agree}%')\n",
    "print(f'Total Variance Between Methods: {np.round(np.mean(np.var(yPreds, axis=0)), 4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
